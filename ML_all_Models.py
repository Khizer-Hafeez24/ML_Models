# -*- coding: utf-8 -*-
"""Untitled22.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NoSVmFPO9HyuBwLK3P50XoPpRL5hHk6d
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_classification, make_regression
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.svm import SVC, SVR
from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor
from sklearn.linear_model import LinearRegression


# Generate sample data for classification and regression

# Generate a binary classification dataset with 2 features
X_classification, y_classification = make_classification(n_samples=100, n_features=2, n_informative=2, n_redundant=0, n_classes=2, random_state=42)

X_regression, y_regression = make_regression(n_samples=100, n_features=1, noise=5, random_state=42)

# Split data for classification and regression
X_train_classification, X_test_classification, y_train_classification, y_test_classification = train_test_split(
    X_classification, y_classification, test_size=0.2, random_state=42)
X_train_regression, X_test_regression, y_train_regression, y_test_regression = train_test_split(
    X_regression, y_regression, test_size=0.2, random_state=42)

# Define classifiers and regressors
classifiers = {
    "Logistic Regression": LogisticRegression(),
    "Decision Tree Classifier": DecisionTreeClassifier(),
    "Random Forest Classifier": RandomForestClassifier(),
    "SVM Classifier": SVC(),
    "K-Nearest Neighbors Classifier": KNeighborsClassifier()
}

regressors = {
    "Linear Regression": LinearRegression(),
    "Decision Tree Regressor": DecisionTreeRegressor(),
    "Random Forest Regressor": RandomForestRegressor(),
    "SVM Regressor": SVR(),
    "K-Nearest Neighbors Regressor": KNeighborsRegressor()
}

# Train classifiers and regressors, and plot outputs
plt.figure(figsize=(18, 10))

# Classification models
for i, (name, classifier) in enumerate(classifiers.items(), 1):
    plt.subplot(2, 3, i)
    classifier.fit(X_train_classification, y_train_classification)
    plt.scatter(X_test_classification[:, 0], X_test_classification[:, 1], c=y_test_classification, cmap='viridis', marker='o', label='True Values')
    plt.title(name)
    plt.xlabel('Feature 1')
    plt.ylabel('Feature 2')
    plt.legend()

plt.tight_layout()
plt.show()

# Regression models
plt.figure(figsize=(18, 10))

for i, (name, regressor) in enumerate(regressors.items(), 1):
    plt.subplot(2, 3, i)
    regressor.fit(X_train_regression, y_train_regression)
    plt.scatter(X_test_regression, y_test_regression, color='blue', label='True Values')
    plt.plot(X_test_regression, regressor.predict(X_test_regression), color='red', label='Predicted Values')
    plt.title(name)
    plt.xlabel('Feature')
    plt.ylabel('Target')
    plt.legend()

plt.tight_layout()
plt.show()